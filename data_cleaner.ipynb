{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3502c62f-a728-442e-bdae-915180a65b77",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "327090a3-aa6f-40cb-a92c-1f4133866cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f714db-c7d6-4585-9387-0b91c6a1c34e",
   "metadata": {},
   "source": [
    "## load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ccbd33d-caf8-464a-8264-b8f27c93130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 11) (49, 9)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "train.set_index('entity_id', inplace=True)\n",
    "test.set_index('entity_id', inplace=True)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2aa72-e608-477d-8239-af909b87584d",
   "metadata": {},
   "source": [
    "## Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9613d84a-01cd-48b9-9050-759c5ddbfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean_and_engineer(df: pd.DataFrame, is_training: bool) -> pd.DataFrame:\n",
    "    \n",
    "    cols_to_clean = [\n",
    "        'revenue', 'overall_score',\n",
    "        'environmental_score', 'social_score', 'governance_score'\n",
    "    ]\n",
    "\n",
    "    if is_training:\n",
    "        cols_to_clean.extend(['target_scope_1', 'target_scope_2'])\n",
    "\n",
    "    # Convert to numeric\n",
    "    for col in cols_to_clean:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Impute score columns with median\n",
    "    score_cols = ['overall_score', 'environmental_score', 'social_score', 'governance_score']\n",
    "    for col in score_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Drop rows missing essential columns\n",
    "    df.dropna(subset=cols_to_clean, inplace=True)\n",
    "\n",
    "    # Log transforms\n",
    "    df['log_revenue'] = np.log1p(df['revenue'])\n",
    "    df.drop(columns=['revenue'], inplace=True)\n",
    "\n",
    "    if is_training:\n",
    "        df['log_scope_1'] = np.log1p(df['target_scope_1'])\n",
    "        df['log_scope_2'] = np.log1p(df['target_scope_2'])\n",
    "        df.drop(columns=['target_scope_1', 'target_scope_2'], inplace=True)\n",
    "\n",
    "    # Drop unused text fields\n",
    "    df.drop(columns=['region_name', 'country_name'], inplace=True, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be108c5-e31b-434a-827d-673346046a6a",
   "metadata": {},
   "source": [
    "## Apply Cleaning & Split Features/Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24e98ce4-edd5-413a-be1c-1d2e681a6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cleaning complete.\n",
      "Train shape: (429, 7) Test shape: (49, 7)\n"
     ]
    }
   ],
   "source": [
    "train_clean = initial_clean_and_engineer(train.copy(), is_training=True)\n",
    "test_clean = initial_clean_and_engineer(test.copy(), is_training=False)\n",
    "\n",
    "TARGETS = ['log_scope_1', 'log_scope_2']\n",
    "X_train = train_clean.drop(columns=TARGETS)\n",
    "Y_train = train_clean[TARGETS]\n",
    "X_test = test_clean.copy()\n",
    "\n",
    "print(\"Initial cleaning complete.\")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc2f4b-6928-4a74-8130-00f65f5f093a",
   "metadata": {},
   "source": [
    "## Merge Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42305c78-7270-4c72-ad77-5c66c605af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting external merges...\n"
     ]
    }
   ],
   "source": [
    "train_features = X_train.copy()\n",
    "test_features  = X_test.copy()\n",
    "\n",
    "print(\"Starting external merges...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d61077-85a1-4a50-aafe-9b0c50d7731f",
   "metadata": {},
   "source": [
    "## External Feature: Sector Revenue Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b562b91-93ef-46aa-9d3e-6e28cc469c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector features merged.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sect = pd.read_csv(\"../data/revenue_distribution_by_sector.csv\")\n",
    "    level_1_sect = (\n",
    "        sect.pivot_table(\n",
    "            values='revenue_pct',\n",
    "            index='entity_id',\n",
    "            columns='nace_level_1_code',\n",
    "            aggfunc='sum',\n",
    "            fill_value=0\n",
    "        )\n",
    "        .add_prefix('sect_')\n",
    "        .add_suffix('_pct')\n",
    "    )\n",
    "\n",
    "    train_features = train_features.merge(level_1_sect, left_index=True, right_index=True, how='left')\n",
    "    test_features = test_features.merge(level_1_sect, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    sector_cols = train_features.filter(like='sect_').columns\n",
    "    train_features[sector_cols] = train_features[sector_cols].fillna(0)\n",
    "    test_features[sector_cols] = test_features[sector_cols].fillna(0)\n",
    "\n",
    "    print(\"Sector features merged.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Sector file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f950729-8caa-4ae2-9f9b-8519b44373cf",
   "metadata": {},
   "source": [
    "## External Feature: Environmental Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53e70171-e920-48fa-9177-16e591eb48aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental features merged.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env = pd.read_csv(\"../data/environmental_activities.csv\")\n",
    "    env_adj = env.groupby('entity_id')['env_score_adjustment'].sum()\n",
    "\n",
    "    train_features = train_features.merge(env_adj, left_index=True, right_index=True, how='left')\n",
    "    test_features = test_features.merge(env_adj, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    train_features['env_score_adjustment'] = train_features['env_score_adjustment'].fillna(0)\n",
    "    test_features['env_score_adjustment'] = test_features['env_score_adjustment'].fillna(0)\n",
    "\n",
    "    print(\"Environmental features merged.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Environmental activity file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b976776-3540-469f-a9e4-24ea007f6282",
   "metadata": {},
   "source": [
    "## External Features: SDG Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3863af91-4da7-4e3a-afaa-be1a810a7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDG features merged.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sdg = pd.read_csv(\"../data/sustainable_development_goals.csv\")\n",
    "    sdg = sdg.drop(columns=['sdg_name'])\n",
    "    sdg = pd.get_dummies(sdg, columns=['sdg_id'])\n",
    "    sdg_agg = sdg.groupby('entity_id').sum()\n",
    "\n",
    "    train_features = train_features.merge(sdg_agg, left_index=True, right_index=True, how='left')\n",
    "    test_features = test_features.merge(sdg_agg, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    sdg_cols = train_features.filter(like='sdg_id_').columns\n",
    "    train_features[sdg_cols] = train_features[sdg_cols].fillna(0)\n",
    "    test_features[sdg_cols] = test_features[sdg_cols].fillna(0)\n",
    "\n",
    "    print(\"SDG features merged.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: SDG file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ca4b7-7711-44c1-8426-ac4e83530708",
   "metadata": {},
   "source": [
    "## final alignment and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f30cf87-be53-49ad-ad5a-4a41c955f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE and alignment complete.\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['region_code', 'country_code']\n",
    "\n",
    "train_features = pd.get_dummies(train_features, columns=categorical_cols, prefix=categorical_cols)\n",
    "test_features = pd.get_dummies(test_features, columns=categorical_cols, prefix=categorical_cols)\n",
    "\n",
    "# Align columns\n",
    "train_cols = train_features.columns.tolist()\n",
    "test_features = test_features.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "print(\"OHE and alignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca630d-b874-4637-8994-b25800817029",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02077f95-825f-4f46-9f54-cd6b8d849d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling complete.\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = train_features.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features[numeric_cols] = scaler.fit_transform(train_features[numeric_cols])\n",
    "test_features[numeric_cols] = scaler.transform(test_features[numeric_cols])\n",
    "\n",
    "print(\"Scaling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452332d-d0da-487f-a14b-7585c44de070",
   "metadata": {},
   "source": [
    "## Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d921bdda-7901-41fe-8616-73f970436f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance selection complete. Features kept: 46\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.05)\n",
    "selector.fit(train_features)\n",
    "\n",
    "selected_columns = train_features.columns[selector.get_support()]\n",
    "\n",
    "train_features = train_features[selected_columns]\n",
    "test_features = test_features[selected_columns]\n",
    "\n",
    "print(\"Variance selection complete. Features kept:\", len(selected_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a06802-6f6f-4c28-9861-f27e7f9e31b5",
   "metadata": {},
   "source": [
    "## Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53702ad8-b10f-43a8-8d43-64a3d81e37dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete!\n",
      "Final train shape: (429, 48)\n",
      "Final test shape: (49, 46)\n"
     ]
    }
   ],
   "source": [
    "final_train = train_features.join(Y_train)\n",
    "final_test = test_features.copy()\n",
    "\n",
    "final_train.to_pickle(\"final_train.pkl\")\n",
    "final_test.to_pickle(\"final_test.pkl\")\n",
    "\n",
    "print(\"Pipeline complete!\")\n",
    "print(\"Final train shape:\", final_train.shape)\n",
    "print(\"Final test shape:\", final_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
